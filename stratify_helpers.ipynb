{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for stratifying data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from snsynth.mst import MSTSynthesizer\n",
    "from snsynth.mwem import MWEMSynthesizer\n",
    "\n",
    "class StratifiedDataset:\n",
    "    \n",
    "    def __init__(self, df, strata_cols, categorical_columns=None, default_bins=10, smallest_strata=0.001):\n",
    "        # create hash mapping for categorical columns\n",
    "        self.num_to_cat = {}\n",
    "        \n",
    "        # convert dataframe to numeric\n",
    "        self.df = self.force_data_categorical_to_numeric(df.copy(), cat_columns=categorical_columns)\n",
    "        # add a column to the dataframe to store the strata index\n",
    "        self.df['strata_index'] = -1\n",
    "        self.strata_cols = strata_cols\n",
    "        self.default_bins = default_bins\n",
    "        self.smallest_strata = smallest_strata\n",
    "\n",
    "        # create strata hash mapping \n",
    "        self.strata_to_id = {}\n",
    "        self.id_to_strata = {}\n",
    "\n",
    "        # for each row in df, add its strata to the hash if its not present\n",
    "        strata_index = 0\n",
    "        for index, row in df.iterrows():\n",
    "            stratum = self.calculate_strata_for_row(row)\n",
    "            if stratum not in self.strata_to_id:\n",
    "                self.strata_to_id[stratum] = strata_index\n",
    "                # reverse mapping\n",
    "                self.id_to_strata[strata_index] = stratum\n",
    "                strata_index += 1\n",
    "            # tag the row with its strata index\n",
    "            self.df.loc[index, 'strata_index'] = self.strata_to_id[stratum]\n",
    "\n",
    "    def calculate_strata_for_row(self, row):\n",
    "        # map a row to a stratum\n",
    "        stratum = []\n",
    "        for col in self.strata_cols:\n",
    "            stratum.append(row[col])\n",
    "        return tuple(stratum)\n",
    "    \n",
    "    def get_strata_count(self):\n",
    "        return len(self.strata_to_id)\n",
    "    \n",
    "    def strata_size_filter(self, strata, verbose=False):\n",
    "        # check if a stratum is too small\n",
    "        check = strata.shape[0] > self.smallest_strata * self.df.shape[0]\n",
    "        if verbose:\n",
    "            print('Strata size:', strata.shape[0], 'Smallest strata size:', self.smallest_strata * self.df.shape[0])\n",
    "        return check\n",
    "\n",
    "    def get_strata_dfs(self, limit_size=False, remove_strata_index=True):\n",
    "        # return a list of dataframes, one for each stratum\n",
    "        strata_dfs = []\n",
    "        for strata_index in range(self.get_strata_count()):\n",
    "            strata = self.df[self.df['strata_index'] == strata_index]\n",
    "            if limit_size:\n",
    "                if self.strata_size_filter(strata):\n",
    "                    strata_dfs.append(strata)\n",
    "            else:\n",
    "                strata_dfs.append(strata)\n",
    "        if remove_strata_index:\n",
    "            for strata_df in strata_dfs:\n",
    "                strata_df.drop('strata_index', axis=1, inplace=True)\n",
    "        return strata_dfs\n",
    "    \n",
    "    def force_data_categorical_to_numeric(self, df, cat_columns=[]):\n",
    "        # convert columns to categorical if they are not already\n",
    "        for col in cat_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype('category')\n",
    "                # save mapping back to original values\n",
    "                self.num_to_cat[col] = dict(enumerate(df[col].cat.categories))\n",
    "                df[col] = df[col].cat.codes\n",
    "        return df\n",
    "\n",
    "class StratifiedSynthesizer:\n",
    "    def __init__(self, synthesizer_class, kwargs=None, epsilon=1.0, smallest_strata=0.001):\n",
    "        self.synthesizer_class = synthesizer_class\n",
    "        self.smallest_strata = smallest_strata\n",
    "        self.strata_synthesizers = None\n",
    "        self.epsilon = epsilon\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def fit(self, df, strata_cols=None, categorical_columns=None):\n",
    "        self.strata_cols = strata_cols\n",
    "        self.categorical_columns = categorical_columns\n",
    "\n",
    "        # Fit normally if no strata_cols are provided\n",
    "        if self.strata_cols is None:\n",
    "            self.stratified_dataset = None\n",
    "            if self.kwargs is None:\n",
    "                synth = self.synthesizer_class(epsilon=self.epsilon)\n",
    "            else:\n",
    "                synth = self.synthesizer_class(epsilon=self.epsilon, **self.kwargs)\n",
    "            synth.fit(df)\n",
    "            self.strata_synthesizers = [synth]\n",
    "            return self\n",
    "        \n",
    "        # Fit on each stratum\n",
    "        self.stratified_dataset = StratifiedDataset(df, self.strata_cols, \n",
    "                                                    smallest_strata=self.smallest_strata, \n",
    "                                                    categorical_columns=self.categorical_columns)\n",
    "        self.strata_synthesizers = []\n",
    "        for strata_df in self.stratified_dataset.get_strata_dfs(limit_size=True):\n",
    "            print('Fitting synthesizer on strata with size', strata_df.shape[0])\n",
    "            if self.kwargs is None:\n",
    "                synth = self.synthesizer_class(epsilon=self.epsilon)\n",
    "            else:\n",
    "                synth = self.synthesizer_class(epsilon=self.epsilon, **self.kwargs)\n",
    "            synth.fit(strata_df)\n",
    "            self.strata_synthesizers.append(synth)\n",
    "        return self\n",
    "\n",
    "    def sample(self, n_samples):\n",
    "        assert self.strata_synthesizers is not None, 'Synthesizer not fitted'\n",
    "        # Sample normally if no strata_cols are provided\n",
    "        if self.stratified_dataset is None:\n",
    "            return self.strata_synthesizers[0].sample(n_samples)\n",
    "        \n",
    "        # Sample from each stratum proportionally\n",
    "        samples = []\n",
    "        for strata_df, synthesizer in zip(self.stratified_dataset.get_strata_dfs(limit_size=True), self.strata_synthesizers):\n",
    "            n = int(n_samples * strata_df.shape[0] / self.stratified_dataset.df.shape[0])\n",
    "            samples.append(synthesizer.sample(n))\n",
    "        return pd.concat(samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                5\n",
       "workclass          8\n",
       "education         16\n",
       "marital-status     7\n",
       "race               5\n",
       "sex                2\n",
       "capitalgain        5\n",
       "capitalloss        5\n",
       "hoursperweek       5\n",
       "target             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import adult dataset from openml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "adult = fetch_openml('adult', version=1, cache=True)\n",
    "target = adult['target']\n",
    "df = adult['data']\n",
    "df['target'] = target\n",
    "remove_columns = True\n",
    "if remove_columns:\n",
    "    # ['fnlwgt', 'education-num','native-country','education','occupation']\n",
    "    columns_to_keep = df.columns[~df.columns.isin(['fnlwgt','native-country','relationship','education-num','occupation'])]\n",
    "    df = df[columns_to_keep]\n",
    "# dimensionality of each df column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28735\n",
       "3    13027\n",
       "1     2377\n",
       "2     2308\n",
       "4     1002\n",
       "7      517\n",
       "5      285\n",
       "9      251\n",
       "8      185\n",
       "6      155\n",
       "Name: strata_index, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric_columns = ['education','workclass','marital-status','occupation','relationship','sex','race','native-country','target']\n",
    "sdf = StratifiedDataset(df, strata_cols=['race','sex'], categorical_columns=non_numeric_columns)\n",
    "sdf.df['strata_index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_mwem = StratifiedSynthesizer(MSTSynthesizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_mwem.fit(df, strata_cols=['race','sex'], categorical_columns=non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_mwem.strata_synthesizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_sample = stratified_mwem.sample(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_mwem.stratified_dataset.force_data_categorical_to_numeric(df, non_numeric_columns).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8099088954857201"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train an sklearn model on the real data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_real, y_train_real)\n",
    "\n",
    "clf.score(X_test_real, y_test_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046882997236156"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train an sklearn model on the synthetic data\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_synth, X_test_synth, y_train_synth, y_test_synth = train_test_split(synth_sample.drop('target', axis=1), synth_sample['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_synth, y_train_synth)\n",
    "\n",
    "clf.score(X_test_real, y_test_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwem = MSTSynthesizer(epsilon=1.0)\n",
    "mwem.fit(stratified_mwem.stratified_dataset.force_data_categorical_to_numeric(df, non_numeric_columns))\n",
    "synth_df_full = mwem.sample(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qj/gh_j11514m37mqtfrlr885k40000gn/T/ipykernel_9341/2142473134.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numeric'"
     ]
    }
   ],
   "source": [
    "class PlotGenerator:\n",
    "    \"\"\"\n",
    "    The synth_data_dict is of the form:\n",
    "    {\n",
    "        'synthesizer': {\n",
    "            '0.1': synth_df, \n",
    "            '0.5': synth_df, \n",
    "            '1.0': synth_df, \n",
    "            '3.0': synth_df,\n",
    "            '6.0': synth_df,\n",
    "        },\n",
    "    }\n",
    "    \"\"\"\n",
    "    def __init__(self, real_data, synth_data_dict, strata_cols, categorical_columns):\n",
    "        self.real_data = real_data\n",
    "        self.synth_data_dict = synth_data_dict\n",
    "        self.strata_cols = strata_cols\n",
    "        self.categorical_columns = categorical_columns\n",
    "\n",
    "    def error_plot_across_epsilons(self):\n",
    "        \"\"\"\n",
    "        Plot the error of the synthetic data for each epsilon\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate the error for each epsilon\n",
    "        errors = []\n",
    "        for epsilon, synth_df in self.synth_data_dict['synthesizer'].items():\n",
    "            errors.append(self.error(synth_df))\n",
    "        \n",
    "        # Plot the error for each epsilon\n",
    "        plt.plot(self.synth_data_dict['synthesizer'].keys(), errors)\n",
    "        plt.xlabel('Epsilon')\n",
    "        plt.ylabel('Error')\n",
    "        plt.title('Error of synthetic data for each epsilon')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to numeric\n",
    "df = df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(df)\n",
    "rank = np.sum(s > 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1326.5604  ,  568.77875 ,  338.82434 ,  298.62393 ,  259.0123  ,\n",
       "        226.29294 ,  184.15746 ,  161.76102 ,  121.585144,  100.41244 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6597d1ed23b894caf154b6750f098a8514a19e03807460ffd2d8425103778dc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
