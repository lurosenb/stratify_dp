{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/synrd/lib/python3.7/site-packages/mbi/__init__.py:15: UserWarning: MixtureInference disabled, please install jax and jaxlib\n",
      "  warnings.warn('MixtureInference disabled, please install jax and jaxlib')\n",
      "/opt/conda/envs/synrd/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RELP']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stratified_dataset import ParallelStratifiedSynthesizer\n",
    "from snsynth.mst import MSTSynthesizer\n",
    "from snsynth.aim import AIMSynthesizer\n",
    "from gem_synthesizer import GEMSynthesizer\n",
    "import dill\n",
    "from helpers.data_utils import get_employment, calculate_dimensionality\n",
    "import itertools\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from stratified_dataset import StratifiedDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fairlearn.metrics import false_positive_rate, false_negative_rate, equalized_odds_ratio, demographic_parity_ratio\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from helpers.send_emails import send_email\n",
    "\n",
    "all_data, features, target, group = get_employment()\n",
    "\n",
    "def load_pickled_model(filename, torch=False):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        model = dill.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the data before: 777600000\n",
      "Dimensionality of the data after: 1215000\n"
     ]
    }
   ],
   "source": [
    "df = all_data.copy()\n",
    "\n",
    "data_dimensionality = calculate_dimensionality(df)\n",
    "print(\"Dimensionality of the data before:\", data_dimensionality)\n",
    "\n",
    "df = df.drop(columns=['CIT', 'MIG', 'DEAR', 'DEYE', 'NATIVITY', 'ANC'])\n",
    "\n",
    "data_dimensionality = calculate_dimensionality(df)\n",
    "print(\"Dimensionality of the data after:\", data_dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_dataframes(train_df, test_df, target_col = 'ESR'):\n",
    "    # Feature columns\n",
    "    feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "    # Convert all columns to categorical\n",
    "    for col in train_df.columns:\n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "\n",
    "    # Prepare the dataset\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[target_col]\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[target_col]\n",
    "\n",
    "    # Train the classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "def min_max_eval(train_df, test_df, strata_cols, target_col = 'ESR'):\n",
    "    # Feature columns\n",
    "    feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "    # Convert all columns to categorical\n",
    "    for col in train_df.columns:\n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "\n",
    "    # Prepare the dataset\n",
    "    combinations = []\n",
    "    for i in range(1, len(strata_cols) + 1):\n",
    "        combinations.extend(list(itertools.combinations(strata_cols, i)))\n",
    "    \n",
    "    accuracies = []\n",
    "    for combination in combinations:\n",
    "        keys_strat = synth_df_strat[list(combination)].value_counts().keys()\n",
    "        for key in keys_strat:\n",
    "            for var in keys_strat.names:\n",
    "                if list(keys_strat.names) == ['SEX', 'RAC1P']:\n",
    "                    subset = synth_df_strat.loc[(synth_df_strat['SEX'] == key[0]) & (synth_df_strat['RAC1P'] == key[1])]\n",
    "                elif list(keys_strat.names) == ['RAC1P']:\n",
    "                    subset = synth_df_strat.loc[(synth_df_strat['RAC1P'] == key[0])]\n",
    "                else:\n",
    "                    subset = synth_df_strat.loc[(synth_df_strat['SEX'] == key[0])]\n",
    "            X_train = train_df[feature_cols]\n",
    "            y_train = train_df[target_col]\n",
    "            X_test = subset[feature_cols]\n",
    "            y_test = subset[target_col]\n",
    "\n",
    "            # Train the classifier\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions on the test set\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            accuracies.append((accuracy, (str(list(combination)), key)))\n",
    "            print((accuracy, (str(list(combination)), key)))\n",
    "    min_tuple = min(accuracies, key=lambda x: x[0])\n",
    "    max_tuple = max(accuracies, key=lambda x: x[0])\n",
    "\n",
    "    return (min_tuple[0], max_tuple[0])\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fairlearn.metrics import false_positive_rate, false_negative_rate, equalized_odds_ratio, demographic_parity_ratio\n",
    "from fairlearn.metrics import MetricFrame\n",
    "\n",
    "def evaluate_on_dataframes_with_fairlearn(train_df, test_df, target_col = 'ESR'):\n",
    "    # Feature columns\n",
    "    feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "    # # Convert all columns to categorical\n",
    "    for col in train_df.columns:\n",
    "        train_df[col] = train_df[col].astype('float')\n",
    "\n",
    "    for col in test_df.columns:\n",
    "        test_df[col] = test_df[col].astype('float')\n",
    "\n",
    "    test_df = test_df.dropna(subset=['SEX', 'RAC1P'])\n",
    "    # Prepare the dataset\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[target_col]\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[target_col]\n",
    "\n",
    "    # Train the classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Compute fairness metrics\n",
    "    metrics = MetricFrame({\n",
    "        'false_positive_rate': false_positive_rate,\n",
    "        'false_negative_rate': false_negative_rate,\n",
    "    }, y_test.values, y_pred, sensitive_features=test_df[['SEX','RAC1P']])\n",
    "\n",
    "    # Compute difference and ratio\n",
    "    m_dif = metrics.difference()\n",
    "    m_ratio = metrics.ratio()\n",
    "    fpr_difference = m_dif['false_positive_rate']\n",
    "    fnr_difference = m_dif['false_negative_rate']\n",
    "    fpr_ratio = m_ratio['false_positive_rate']\n",
    "    fnr_ratio = m_ratio['false_negative_rate']\n",
    "\n",
    "    # Define sensitive features\n",
    "    sensitive_features_test = X_test[['SEX','RAC1P']]  # Replace 'strata_cols' with the actual column name(s)\n",
    "\n",
    "    # Compute equalized odds ratio\n",
    "    eor = equalized_odds_ratio(y_true=y_test, \n",
    "                            y_pred=y_pred, \n",
    "                            sensitive_features=sensitive_features_test)\n",
    "\n",
    "    # Compute equalized odds ratio\n",
    "    dpr = demographic_parity_ratio(y_true=y_test, \n",
    "                            y_pred=y_pred, \n",
    "                            sensitive_features=sensitive_features_test)\n",
    "\n",
    "    results = {\n",
    "        'Accuracy': accuracy,\n",
    "        'False_positive_rate': metrics.overall['false_positive_rate'],\n",
    "        'False_negative_rate': metrics.overall['false_negative_rate'],\n",
    "        'FPR_difference': fpr_difference,\n",
    "        'FNR_difference': fnr_difference,\n",
    "        'FPR_ratio': fpr_ratio,\n",
    "        'FNR_ratio': fnr_ratio,\n",
    "        'Equalized_odds_ratio': eor,\n",
    "        'Demographic_parity_ratio': dpr,\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subgroup_key(group, groupby_cols):\n",
    "    key = []\n",
    "    for col in groupby_cols:\n",
    "        unique_values = group[col].unique()\n",
    "        if len(unique_values) == 1:\n",
    "            key.append((col, unique_values[0]))\n",
    "        else:\n",
    "            print(f\"More than one unique value found for column '{col}' in the given group.\")\n",
    "            print(f\"Unique values found: {unique_values}\")\n",
    "            raise ValueError(f\"More than one unique value found for column '{col}' in the given group.\")\n",
    "    return tuple(key)\n",
    "\n",
    "def create_subgroups_dict(X, groupby_cols):\n",
    "    subgroups = {}\n",
    "    for _, group in X.groupby(groupby_cols):\n",
    "        if not group.empty:\n",
    "            key = get_subgroup_key(group, groupby_cols)\n",
    "            subgroups[key] = group\n",
    "        else:\n",
    "            print('This weird thing happens sometimes where a group is empty. Not sure why.')\n",
    "    return subgroups\n",
    "    \n",
    "def parity_error_synth_data(X, X_prime, groupby_cols, f, omega):\n",
    "    subgroups_real = create_subgroups_dict(X, groupby_cols)\n",
    "    subgroups_synth = create_subgroups_dict(X_prime, groupby_cols)\n",
    "    f_values_real = []\n",
    "    f_values_synth = []\n",
    "\n",
    "    # Calculate f and M values for each stratum\n",
    "    # for key in keys_for_comparison:\n",
    "    for key, s in subgroups_real.items():\n",
    "        s = subgroups_real[key]\n",
    "        f_value_real = f(s)\n",
    "        f_values_real.append(f_value_real)\n",
    "        \n",
    "        if key in subgroups_synth:\n",
    "            f_value_synth = f(subgroups_synth[key])\n",
    "        else:\n",
    "            print(subgroups_real.keys())\n",
    "            print(subgroups_synth.keys())\n",
    "            print((f'Should not happen: {key} not in subgroups_synth'))\n",
    "            f_value_synth = f(X_prime)\n",
    "\n",
    "        f_values_synth.append(f_value_synth)\n",
    "\n",
    "    # Calculate the global f and M values\n",
    "    f_global = f(X)\n",
    "    f_synth_global = f(X_prime)\n",
    "\n",
    "    # Compute the parity error\n",
    "    beta = omega * (abs(f_global - f_synth_global) / f_global) + sum([(abs(t - s) / t) for t, s in zip(f_values_real, f_values_synth)])\n",
    "\n",
    "    return beta\n",
    "\n",
    "def calculate_disparity(real_train_df, synth_df, strata_cols, func):\n",
    "    assert len(strata_cols) > 0, \"strata_cols must be a list with at least one element\"\n",
    "\n",
    "    # Create multi-index DataFrames grouped by strata_cols\n",
    "    real_grouped = real_train_df.groupby(strata_cols)\n",
    "    synth_grouped = synth_df.groupby(strata_cols)\n",
    "\n",
    "    # Initialize disparity as negative infinity\n",
    "    max_disparity = float('-inf')\n",
    "    max_key = None\n",
    "\n",
    "    # Iterate over unique combinations of strata_cols\n",
    "    for key in real_grouped.groups.keys():\n",
    "        # Check if the group also exists in the synthetic data\n",
    "        if key in synth_grouped.groups.keys():\n",
    "            real_group = real_grouped.get_group(key)\n",
    "            synth_group = synth_grouped.get_group(key)\n",
    "\n",
    "            # Apply the function to the real and synthetic groups\n",
    "            real_result = func(real_group)\n",
    "            synth_result = func(synth_group)\n",
    "\n",
    "            # Calculate the absolute difference normalized\n",
    "            disparity = abs((real_result - synth_result) / real_result) \n",
    "            # If this disparity is greater than the current maximum, update maximum\n",
    "            for disp in disparity:\n",
    "                if not np.isinf(disp):\n",
    "                    if disp > max_disparity:\n",
    "                        max_disparity = disp\n",
    "                        max_key = key\n",
    "                        \n",
    "    return max_disparity, max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_f(df):\n",
    "    return df.astype(float).mean().values\n",
    "\n",
    "def add_row_to_performance_df(performance_df, synth_class, synth_df, epsilon, real_train_df, real_test_df, name_combo, omega = 0.2, strata_cols = ['SEX', 'RAC1P']):\n",
    "    result_dict = evaluate_on_dataframes_with_fairlearn(synth_df, real_test_df)\n",
    "    row_dict = {\n",
    "        'Synthesizer': synth_class.__name__ + \"_\" + name_combo,\n",
    "        'Epsilon': epsilon,\n",
    "    }\n",
    "    \n",
    "    for k, v in result_dict.items():\n",
    "        row_dict[k] = v\n",
    "\n",
    "    for combination in combinations:\n",
    "        strata_cols = list(combination)\n",
    "\n",
    "        # Calculate parity error\n",
    "        parity_error = parity_error_synth_data(real_train_df, synth_df, strata_cols, mean_f, omega)\n",
    "        row_dict[str(strata_cols)+\"_parity_error\"] = parity_error\n",
    "\n",
    "        # Calculate max disparity\n",
    "        max_disparity = calculate_disparity(real_train_df, synth_df, strata_cols, mean_f)\n",
    "        row_dict[str(strata_cols)+\"_max_disparity\"] = max_disparity\n",
    "\n",
    "\n",
    "    performance_df = performance_df.append(row_dict, ignore_index=True)\n",
    "    return performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 1\n",
    "\n",
    "synthesizers = [MSTSynthesizer, AIMSynthesizer, GEMSynthesizer] #[MSTSynthesizer, AIMSynthesizer] GEMSynthesizer, MSTSynthesizer, \n",
    "epsilons = [0.01, 0.05, 0.1, 0.5, 1.0, 5.0]\n",
    "omega = 1/12 # (1/k is the default value in the paper)\n",
    "strata_cols = ['SEX', 'RAC1P']\n",
    "\n",
    "# Generate all possible combinations of the given column names\n",
    "combinations = []\n",
    "for i in range(1, len(strata_cols) + 1):\n",
    "    combinations.extend(list(itertools.combinations(strata_cols, i)))\n",
    "\n",
    "def step_email(iter):\n",
    "    subject = f\"COMPLETE: Iter {iter})\"\n",
    "    body = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    log_email_target = 'lr2872@nyu.edu'\n",
    "    send_email(subject, body, log_email_target)\n",
    "\n",
    "def force_data_categorical_to_numeric(df, cat_columns=[]):\n",
    "    # convert columns to categorical if they are not already\n",
    "    for col in cat_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "            df[col] = df[col].cat.codes\n",
    "    return df\n",
    "\n",
    "def evaluate_model(model_filename, synth_class, epsilon, real_train_df, real_test_df, name_combo, omega, smallest_intersection):\n",
    "    model = load_pickled_model(model_filename)\n",
    "    synth_df = model.sample(real_train_df.shape[0])\n",
    "    try:\n",
    "        if name_combo == \"vanilla\":\n",
    "            if synth_class.__name__ == 'GEMSynthesizer':\n",
    "                synth_df = synth_df.loc[synth_df.apply(lambda row: (('SEX', row['SEX']), ('RAC1P', row['RAC1P'])) in smallest_intersection, axis=1)]\n",
    "            else:\n",
    "                synth_df = force_data_categorical_to_numeric(synth_df, cat_columns=synth_df.columns)\n",
    "        performance_df = add_row_to_performance_df(pd.DataFrame(), synth_class, synth_df, epsilon, real_train_df, real_test_df, name_combo, omega)\n",
    "        return performance_df\n",
    "    except:\n",
    "        print('Failed ' + model_filename)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def determine_limiting_synth(real_train_df, real_test_df, synthesizers, epsilon=0.1, strata_cols=['SEX','RAC1P'], seed=0):\n",
    "    smallest_intersection = None\n",
    "    for synth_class in synthesizers:\n",
    "        for combination in combinations:\n",
    "            name_combo = str(\"_\".join(combination))\n",
    "            model_filename = f\"models/{synth_class.__name__}_epsilon_{epsilon}_{name_combo}_seed_{seed}.dill\"\n",
    "            synth_df = load_pickled_model(model_filename).sample(100000)\n",
    "            intersection = set(create_subgroups_dict(real_train_df, ['SEX', 'RAC1P']).keys()).intersection(set(create_subgroups_dict(synth_df, ['SEX', 'RAC1P']).keys()))\n",
    "            print(\"Intersection: \", len(intersection))\n",
    "            if smallest_intersection is None or len(intersection) < len(smallest_intersection):\n",
    "                smallest_intersection = intersection\n",
    "    real_train_df = real_train_df.loc[real_train_df.apply(lambda row: (('SEX', row['SEX']), ('RAC1P', row['RAC1P'])) in smallest_intersection, axis=1)]\n",
    "    real_test_df = real_test_df.loc[real_test_df.apply(lambda row: (('SEX', row['SEX']), ('RAC1P', row['RAC1P'])) in smallest_intersection, axis=1)]\n",
    "    print(\"Smallest intersection: \", len(smallest_intersection))\n",
    "    return real_train_df, real_test_df, smallest_intersection\n",
    "\n",
    "def generate_performance_plots(real_train_df, real_test_df, combinations, synthesizers, epsilons):\n",
    "    dataframe_cols = ['Synthesizer', 'Epsilon', 'Accuracy']\n",
    "    for combination in list(combinations):\n",
    "        strata_cols = list(combination)\n",
    "        dataframe_cols.append(str(strata_cols))\n",
    "    performance_df = pd.DataFrame(columns=dataframe_cols)\n",
    "\n",
    "    # We want to only fit on rows that are represented by all synthesizers\n",
    "    real_train_df, real_test_df, smallest_intersection = determine_limiting_synth(real_train_df, real_test_df, synthesizers)\n",
    "    print(real_train_df.groupby(['RAC1P','SEX']).count())\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for seed in [0,1,2,3,4]:\n",
    "            for synth_class in synthesizers:\n",
    "                for epsilon in epsilons:\n",
    "                    model_filename = f\"models/{synth_class.__name__}_epsilon_{epsilon}_seed_{seed}.dill\"\n",
    "                    futures.append(executor.submit(evaluate_model, model_filename, synth_class, epsilon, real_train_df, real_test_df, \"vanilla\", omega, smallest_intersection))\n",
    "\n",
    "                    for combination in combinations:\n",
    "                        name_combo = str(\"_\".join(combination))\n",
    "                        model_filename = f\"models/{synth_class.__name__}_epsilon_{epsilon}_{name_combo}_seed_{seed}.dill\"\n",
    "                        futures.append(executor.submit(evaluate_model, model_filename, synth_class, epsilon, real_train_df, real_test_df, name_combo, omega, smallest_intersection))\n",
    "\n",
    "        for i, future in enumerate(tqdm(as_completed(futures), total=len(futures))):\n",
    "            result_df = future.result()\n",
    "            performance_df = performance_df.append(result_df, ignore_index=True)\n",
    "            if (i % 50) == 0:\n",
    "                step_email(i)\n",
    "\n",
    "    performance_df.to_pickle('new_performance.pkl')\n",
    "\n",
    "    return performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection:  18\n",
      "Intersection:  14\n",
      "Intersection:  12\n",
      "Intersection:  18\n",
      "Intersection:  14\n",
      "Intersection:  12\n",
      "Intersection:  18\n",
      "Intersection:  14\n",
      "Intersection:  12\n",
      "Smallest intersection:  12\n",
      "            AGEP   SCHL    MAR    DIS    ESP    MIL   DREM    ESR\n",
      "RAC1P SEX                                                        \n",
      "0     0    54226  54226  54226  54226  54226  54226  54226  54226\n",
      "      1    56616  56616  56616  56616  56616  56616  56616  56616\n",
      "1     0     8892   8892   8892   8892   8892   8892   8892   8892\n",
      "      1    10346  10346  10346  10346  10346  10346  10346  10346\n",
      "2     0      221    221    221    221    221    221    221    221\n",
      "      1      181    181    181    181    181    181    181    181\n",
      "5     0     6438   6438   6438   6438   6438   6438   6438   6438\n",
      "      1     7121   7121   7121   7121   7121   7121   7121   7121\n",
      "7     0     4224   4224   4224   4224   4224   4224   4224   4224\n",
      "      1     4532   4532   4532   4532   4532   4532   4532   4532\n",
      "8     0     2096   2096   2096   2096   2096   2096   2096   2096\n",
      "      1     2407   2407   2407   2407   2407   2407   2407   2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/360 [01:48<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the real dataset for evaluation\n",
    "df_numeric = force_data_categorical_to_numeric(df, cat_columns=df.columns)\n",
    "X_real = df_numeric.drop('ESR', axis=1)\n",
    "y_real = df_numeric['ESR']\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X_real, y_real, test_size=0.2, random_state=42)\n",
    "train_df_real = X_train_real.copy()\n",
    "train_df_real['ESR'] = y_train_real\n",
    "test_df_real = X_test_real.copy()\n",
    "test_df_real['ESR'] = y_test_real\n",
    "\n",
    "# Generate the performance plots\n",
    "performance_df = generate_performance_plots(train_df_real, test_df_real, list(combinations), synthesizers, epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email was sent to lr2872@nyu.edu with Email Id: 188137523b6c9dda\n"
     ]
    }
   ],
   "source": [
    "step_email(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynRD",
   "language": "python",
   "name": "synrd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6597d1ed23b894caf154b6750f098a8514a19e03807460ffd2d8425103778dc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
